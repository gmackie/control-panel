#!/usr/bin/env python3
"""
Edge Computing Orchestration System
Manages workload distribution, deployment, and monitoring across edge locations
"""

import os
import json
import asyncio
import hashlib
import time
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, asdict, field
from datetime import datetime, timedelta
from enum import Enum
import numpy as np
from collections import defaultdict
import websocket
import threading
import queue

class EdgeNodeType(Enum):
    """Types of edge nodes"""
    MICRO_DATACENTER = "micro_datacenter"
    GATEWAY = "gateway"
    IOT_HUB = "iot_hub"
    MOBILE_EDGE = "mobile_edge"
    RETAIL_EDGE = "retail_edge"
    INDUSTRIAL_EDGE = "industrial_edge"
    CDN_POP = "cdn_pop"
    VEHICLE_EDGE = "vehicle_edge"

class WorkloadType(Enum):
    """Types of edge workloads"""
    REAL_TIME_ANALYTICS = "real_time_analytics"
    AI_INFERENCE = "ai_inference"
    VIDEO_PROCESSING = "video_processing"
    IOT_PROCESSING = "iot_processing"
    CONTENT_CACHING = "content_caching"
    DATA_FILTERING = "data_filtering"
    SECURITY_SCANNING = "security_scanning"
    PROTOCOL_TRANSLATION = "protocol_translation"

class DeploymentStrategy(Enum):
    """Edge deployment strategies"""
    LATENCY_OPTIMIZED = "latency_optimized"
    COST_OPTIMIZED = "cost_optimized"
    RELIABILITY_OPTIMIZED = "reliability_optimized"
    BANDWIDTH_OPTIMIZED = "bandwidth_optimized"
    ENERGY_OPTIMIZED = "energy_optimized"
    COMPLIANCE_BASED = "compliance_based"

@dataclass
class EdgeNode:
    """Edge node representation"""
    id: str
    name: str
    type: EdgeNodeType
    location: Dict[str, Any]  # lat, lon, city, country, region
    capacity: Dict[str, float]  # cpu, memory, storage, network
    available_capacity: Dict[str, float]
    status: str  # online, offline, degraded, maintenance
    latency_to_cloud: float  # milliseconds
    bandwidth_to_cloud: float  # Mbps
    power_source: str  # grid, battery, solar, hybrid
    connectivity: List[str]  # 5G, LTE, WiFi, Ethernet, Satellite
    supported_workloads: List[WorkloadType]
    cost_per_hour: float
    metadata: Dict[str, Any]
    last_heartbeat: datetime
    health_score: float  # 0-100

@dataclass
class EdgeWorkload:
    """Edge workload definition"""
    id: str
    name: str
    type: WorkloadType
    requirements: Dict[str, float]  # cpu, memory, storage, network
    priority: int  # 1-10
    latency_requirement: Optional[float]  # max milliseconds
    data_locality: Optional[str]  # geographic constraint
    deployment_strategy: DeploymentStrategy
    replicas: int
    container_image: str
    environment_vars: Dict[str, str]
    dependencies: List[str]
    status: str  # pending, deploying, running, failed
    deployed_nodes: List[str]
    created_at: datetime
    metadata: Dict[str, Any]

@dataclass
class EdgeDeployment:
    """Edge deployment instance"""
    id: str
    workload_id: str
    node_id: str
    status: str  # pending, running, stopped, failed
    started_at: datetime
    resource_usage: Dict[str, float]
    performance_metrics: Dict[str, float]
    logs: List[str]
    health_checks: Dict[str, bool]

@dataclass
class EdgeMetrics:
    """Edge node and workload metrics"""
    node_id: str
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    storage_usage: float
    network_in: float
    network_out: float
    latency: float
    error_rate: float
    request_rate: float
    temperature: Optional[float]
    power_consumption: Optional[float]

class EdgeOrchestrator:
    """Main edge orchestration engine"""
    
    def __init__(self):
        self.nodes: Dict[str, EdgeNode] = {}
        self.workloads: Dict[str, EdgeWorkload] = {}
        self.deployments: Dict[str, EdgeDeployment] = {}
        self.metrics_history: List[EdgeMetrics] = []
        self.placement_cache = {}
        self.event_queue = queue.Queue()
        self.websocket_clients = []
        
        # Orchestration parameters
        self.rebalance_interval = timedelta(minutes=5)
        self.health_check_interval = timedelta(seconds=30)
        self.last_rebalance = datetime.now()
        self.last_health_check = datetime.now()
        
        # Initialize sample edge nodes
        self._initialize_edge_nodes()
    
    def _initialize_edge_nodes(self):
        """Initialize sample edge nodes for testing"""
        
        # US East Coast micro datacenter
        self.register_node(EdgeNode(
            id="edge-us-east-1",
            name="US East Micro DC",
            type=EdgeNodeType.MICRO_DATACENTER,
            location={
                "lat": 40.7128, "lon": -74.0060,
                "city": "New York", "country": "USA", "region": "us-east"
            },
            capacity={"cpu": 64, "memory": 256, "storage": 2000, "network": 10000},
            available_capacity={"cpu": 48, "memory": 192, "storage": 1500, "network": 8000},
            status="online",
            latency_to_cloud=5,
            bandwidth_to_cloud=10000,
            power_source="grid",
            connectivity=["Ethernet", "5G"],
            supported_workloads=list(WorkloadType),
            cost_per_hour=0.50,
            metadata={"tier": "premium", "sla": "99.99%"},
            last_heartbeat=datetime.now(),
            health_score=95.0
        ))
        
        # West Coast IoT hub
        self.register_node(EdgeNode(
            id="edge-us-west-1",
            name="SF IoT Hub",
            type=EdgeNodeType.IOT_HUB,
            location={
                "lat": 37.7749, "lon": -122.4194,
                "city": "San Francisco", "country": "USA", "region": "us-west"
            },
            capacity={"cpu": 32, "memory": 128, "storage": 1000, "network": 5000},
            available_capacity={"cpu": 24, "memory": 96, "storage": 800, "network": 4000},
            status="online",
            latency_to_cloud=8,
            bandwidth_to_cloud=5000,
            power_source="hybrid",
            connectivity=["LTE", "WiFi", "Ethernet"],
            supported_workloads=[
                WorkloadType.IOT_PROCESSING,
                WorkloadType.DATA_FILTERING,
                WorkloadType.REAL_TIME_ANALYTICS
            ],
            cost_per_hour=0.30,
            metadata={"specialization": "iot", "protocols": ["MQTT", "CoAP"]},
            last_heartbeat=datetime.now(),
            health_score=92.0
        ))
        
        # European mobile edge
        self.register_node(EdgeNode(
            id="edge-eu-west-1",
            name="London Mobile Edge",
            type=EdgeNodeType.MOBILE_EDGE,
            location={
                "lat": 51.5074, "lon": -0.1278,
                "city": "London", "country": "UK", "region": "eu-west"
            },
            capacity={"cpu": 16, "memory": 64, "storage": 500, "network": 2000},
            available_capacity={"cpu": 12, "memory": 48, "storage": 400, "network": 1500},
            status="online",
            latency_to_cloud=12,
            bandwidth_to_cloud=2000,
            power_source="grid",
            connectivity=["5G", "LTE"],
            supported_workloads=[
                WorkloadType.AI_INFERENCE,
                WorkloadType.VIDEO_PROCESSING,
                WorkloadType.CONTENT_CACHING
            ],
            cost_per_hour=0.35,
            metadata={"carrier": "Vodafone", "spectrum": "5G"},
            last_heartbeat=datetime.now(),
            health_score=88.0
        ))
        
        # Asia Pacific CDN PoP
        self.register_node(EdgeNode(
            id="edge-ap-south-1",
            name="Singapore CDN PoP",
            type=EdgeNodeType.CDN_POP,
            location={
                "lat": 1.3521, "lon": 103.8198,
                "city": "Singapore", "country": "Singapore", "region": "ap-south"
            },
            capacity={"cpu": 48, "memory": 192, "storage": 5000, "network": 20000},
            available_capacity={"cpu": 36, "memory": 144, "storage": 4000, "network": 16000},
            status="online",
            latency_to_cloud=15,
            bandwidth_to_cloud=20000,
            power_source="grid",
            connectivity=["Ethernet"],
            supported_workloads=[
                WorkloadType.CONTENT_CACHING,
                WorkloadType.VIDEO_PROCESSING,
                WorkloadType.SECURITY_SCANNING
            ],
            cost_per_hour=0.40,
            metadata={"cache_size": "5TB", "cache_hit_ratio": 0.85},
            last_heartbeat=datetime.now(),
            health_score=94.0
        ))
        
        # Industrial edge
        self.register_node(EdgeNode(
            id="edge-industrial-1",
            name="Factory Floor Edge",
            type=EdgeNodeType.INDUSTRIAL_EDGE,
            location={
                "lat": 41.8781, "lon": -87.6298,
                "city": "Chicago", "country": "USA", "region": "us-central"
            },
            capacity={"cpu": 24, "memory": 96, "storage": 750, "network": 1000},
            available_capacity={"cpu": 18, "memory": 72, "storage": 600, "network": 800},
            status="online",
            latency_to_cloud=10,
            bandwidth_to_cloud=1000,
            power_source="grid",
            connectivity=["Ethernet", "WiFi"],
            supported_workloads=[
                WorkloadType.REAL_TIME_ANALYTICS,
                WorkloadType.AI_INFERENCE,
                WorkloadType.PROTOCOL_TRANSLATION
            ],
            cost_per_hour=0.25,
            metadata={"protocols": ["OPC-UA", "Modbus"], "safety_certified": True},
            last_heartbeat=datetime.now(),
            health_score=90.0
        ))
    
    def register_node(self, node: EdgeNode) -> bool:
        """Register a new edge node"""
        self.nodes[node.id] = node
        self._emit_event("node_registered", {"node_id": node.id, "type": node.type.value})
        print(f"‚úÖ Registered edge node: {node.name} ({node.type.value})")
        return True
    
    def deploy_workload(self, workload: EdgeWorkload) -> List[EdgeDeployment]:
        """Deploy workload to optimal edge nodes"""
        self.workloads[workload.id] = workload
        
        # Find optimal placement
        placement_plan = self._calculate_optimal_placement(workload)
        
        if not placement_plan:
            print(f"‚ùå No suitable nodes found for workload {workload.name}")
            workload.status = "failed"
            return []
        
        deployments = []
        for node_id in placement_plan:
            deployment = self._deploy_to_node(workload, node_id)
            if deployment:
                deployments.append(deployment)
                workload.deployed_nodes.append(node_id)
        
        workload.status = "running" if deployments else "failed"
        return deployments
    
    def _calculate_optimal_placement(self, workload: EdgeWorkload) -> List[str]:
        """Calculate optimal node placement for workload"""
        suitable_nodes = []
        
        for node_id, node in self.nodes.items():
            if node.status != "online":
                continue
            
            # Check workload type support
            if workload.type not in node.supported_workloads:
                continue
            
            # Check resource availability
            if not self._check_resource_availability(node, workload):
                continue
            
            # Check latency requirements
            if workload.latency_requirement and node.latency_to_cloud > workload.latency_requirement:
                continue
            
            # Check data locality
            if workload.data_locality and node.location.get("region") != workload.data_locality:
                continue
            
            # Calculate placement score
            score = self._calculate_placement_score(node, workload)
            suitable_nodes.append((node_id, score))
        
        # Sort by score and select top nodes for replicas
        suitable_nodes.sort(key=lambda x: x[1], reverse=True)
        selected_nodes = [node_id for node_id, _ in suitable_nodes[:workload.replicas]]
        
        return selected_nodes
    
    def _check_resource_availability(self, node: EdgeNode, workload: EdgeWorkload) -> bool:
        """Check if node has sufficient resources"""
        for resource, required in workload.requirements.items():
            if node.available_capacity.get(resource, 0) < required:
                return False
        return True
    
    def _calculate_placement_score(self, node: EdgeNode, workload: EdgeWorkload) -> float:
        """Calculate placement score based on deployment strategy"""
        score = 0.0
        
        if workload.deployment_strategy == DeploymentStrategy.LATENCY_OPTIMIZED:
            # Lower latency = higher score
            score = 100 - node.latency_to_cloud
            
        elif workload.deployment_strategy == DeploymentStrategy.COST_OPTIMIZED:
            # Lower cost = higher score
            score = 100 - (node.cost_per_hour * 100)
            
        elif workload.deployment_strategy == DeploymentStrategy.RELIABILITY_OPTIMIZED:
            # Higher health score = higher score
            score = node.health_score
            
        elif workload.deployment_strategy == DeploymentStrategy.BANDWIDTH_OPTIMIZED:
            # Higher bandwidth = higher score
            score = min(100, node.bandwidth_to_cloud / 100)
            
        elif workload.deployment_strategy == DeploymentStrategy.ENERGY_OPTIMIZED:
            # Prefer renewable energy sources
            energy_scores = {"solar": 100, "hybrid": 75, "battery": 50, "grid": 25}
            score = energy_scores.get(node.power_source, 0)
            
        else:  # COMPLIANCE_BASED
            # Check region compliance
            score = 100 if node.location.get("region") == workload.data_locality else 0
        
        # Apply priority weighting
        score *= (workload.priority / 10)
        
        return score
    
    def _deploy_to_node(self, workload: EdgeWorkload, node_id: str) -> Optional[EdgeDeployment]:
        """Deploy workload to specific node"""
        node = self.nodes.get(node_id)
        if not node:
            return None
        
        # Create deployment
        deployment = EdgeDeployment(
            id=f"dep-{workload.id}-{node_id}",
            workload_id=workload.id,
            node_id=node_id,
            status="running",
            started_at=datetime.now(),
            resource_usage=workload.requirements.copy(),
            performance_metrics={},
            logs=[f"Deployment started on {node.name}"],
            health_checks={"liveness": True, "readiness": True}
        )
        
        # Update node available capacity
        for resource, usage in workload.requirements.items():
            if resource in node.available_capacity:
                node.available_capacity[resource] -= usage
        
        self.deployments[deployment.id] = deployment
        self._emit_event("deployment_created", {
            "deployment_id": deployment.id,
            "workload": workload.name,
            "node": node.name
        })
        
        print(f"üì¶ Deployed {workload.name} to {node.name}")
        return deployment
    
    def rebalance_workloads(self) -> Dict[str, Any]:
        """Rebalance workloads across edge nodes"""
        migrations = []
        
        for workload_id, workload in self.workloads.items():
            if workload.status != "running":
                continue
            
            # Check if current placement is still optimal
            current_nodes = workload.deployed_nodes
            optimal_nodes = self._calculate_optimal_placement(workload)
            
            if set(current_nodes) != set(optimal_nodes):
                # Migration needed
                migrations.append({
                    "workload": workload.name,
                    "from_nodes": current_nodes,
                    "to_nodes": optimal_nodes,
                    "reason": "optimization"
                })
                
                # Perform migration
                self._migrate_workload(workload, optimal_nodes)
        
        self.last_rebalance = datetime.now()
        return {
            "timestamp": datetime.now().isoformat(),
            "migrations": migrations,
            "total_workloads": len(self.workloads),
            "total_nodes": len(self.nodes)
        }
    
    def _migrate_workload(self, workload: EdgeWorkload, new_nodes: List[str]):
        """Migrate workload to new nodes"""
        # Remove old deployments
        for deployment_id in list(self.deployments.keys()):
            deployment = self.deployments[deployment_id]
            if deployment.workload_id == workload.id:
                self._remove_deployment(deployment_id)
        
        # Clear deployed nodes
        workload.deployed_nodes = []
        
        # Create new deployments
        for node_id in new_nodes:
            deployment = self._deploy_to_node(workload, node_id)
            if deployment:
                workload.deployed_nodes.append(node_id)
    
    def _remove_deployment(self, deployment_id: str):
        """Remove a deployment and free resources"""
        deployment = self.deployments.get(deployment_id)
        if not deployment:
            return
        
        # Free node resources
        node = self.nodes.get(deployment.node_id)
        if node:
            for resource, usage in deployment.resource_usage.items():
                if resource in node.available_capacity:
                    node.available_capacity[resource] += usage
        
        del self.deployments[deployment_id]
    
    def collect_metrics(self) -> List[EdgeMetrics]:
        """Collect metrics from all edge nodes"""
        metrics = []
        
        for node in self.nodes.values():
            # Simulate metric collection
            metric = EdgeMetrics(
                node_id=node.id,
                timestamp=datetime.now(),
                cpu_usage=(node.capacity["cpu"] - node.available_capacity["cpu"]) / node.capacity["cpu"] * 100,
                memory_usage=(node.capacity["memory"] - node.available_capacity["memory"]) / node.capacity["memory"] * 100,
                storage_usage=(node.capacity["storage"] - node.available_capacity["storage"]) / node.capacity["storage"] * 100,
                network_in=np.random.uniform(100, 1000),  # Mbps
                network_out=np.random.uniform(50, 500),  # Mbps
                latency=node.latency_to_cloud + np.random.uniform(-2, 2),
                error_rate=np.random.uniform(0, 0.01),
                request_rate=np.random.uniform(100, 10000),
                temperature=np.random.uniform(20, 40) if node.type == EdgeNodeType.INDUSTRIAL_EDGE else None,
                power_consumption=np.random.uniform(50, 200) if node.power_source != "grid" else None
            )
            
            metrics.append(metric)
            self.metrics_history.append(metric)
        
        # Keep only recent metrics
        cutoff = datetime.now() - timedelta(hours=24)
        self.metrics_history = [m for m in self.metrics_history if m.timestamp > cutoff]
        
        return metrics
    
    def predict_failures(self) -> List[Dict]:
        """Predict potential node failures using ML"""
        predictions = []
        
        for node in self.nodes.values():
            # Simple failure prediction based on health score trend
            recent_metrics = [m for m in self.metrics_history 
                            if m.node_id == node.id and 
                            m.timestamp > datetime.now() - timedelta(hours=1)]
            
            if recent_metrics:
                avg_error_rate = np.mean([m.error_rate for m in recent_metrics])
                
                if avg_error_rate > 0.005 or node.health_score < 80:
                    failure_probability = min(0.9, avg_error_rate * 100 + (100 - node.health_score) / 100)
                    
                    predictions.append({
                        "node_id": node.id,
                        "node_name": node.name,
                        "failure_probability": failure_probability,
                        "predicted_time": (datetime.now() + timedelta(hours=np.random.uniform(1, 24))).isoformat(),
                        "recommended_action": "Migrate critical workloads" if failure_probability > 0.5 else "Monitor closely"
                    })
        
        return predictions
    
    def optimize_energy_usage(self) -> Dict:
        """Optimize energy usage across edge nodes"""
        optimizations = {
            "current_consumption": 0,
            "optimized_consumption": 0,
            "savings_percentage": 0,
            "recommendations": []
        }
        
        for node in self.nodes.values():
            # Estimate current consumption
            utilization = (node.capacity["cpu"] - node.available_capacity["cpu"]) / node.capacity["cpu"]
            base_power = 100  # Watts
            current_power = base_power * (1 + utilization)
            optimizations["current_consumption"] += current_power
            
            # Optimization recommendations
            if utilization < 0.2 and node.power_source == "grid":
                optimizations["recommendations"].append({
                    "node": node.name,
                    "action": "Consider shutting down or consolidating workloads",
                    "potential_savings": current_power * 0.8
                })
                optimizations["optimized_consumption"] += current_power * 0.2
            elif utilization > 0.8:
                optimizations["recommendations"].append({
                    "node": node.name,
                    "action": "Distribute load to reduce power consumption",
                    "potential_savings": current_power * 0.1
                })
                optimizations["optimized_consumption"] += current_power * 0.9
            else:
                optimizations["optimized_consumption"] += current_power
        
        if optimizations["current_consumption"] > 0:
            optimizations["savings_percentage"] = (
                (optimizations["current_consumption"] - optimizations["optimized_consumption"]) /
                optimizations["current_consumption"] * 100
            )
        
        return optimizations
    
    def get_edge_topology(self) -> Dict:
        """Get current edge topology and connections"""
        topology = {
            "nodes": [],
            "connections": [],
            "workload_distribution": {},
            "geographic_coverage": {}
        }
        
        # Node information
        for node in self.nodes.values():
            topology["nodes"].append({
                "id": node.id,
                "name": node.name,
                "type": node.type.value,
                "location": node.location,
                "status": node.status,
                "workload_count": len([d for d in self.deployments.values() if d.node_id == node.id])
            })
            
            # Geographic coverage
            region = node.location.get("region", "unknown")
            if region not in topology["geographic_coverage"]:
                topology["geographic_coverage"][region] = []
            topology["geographic_coverage"][region].append(node.name)
        
        # Workload distribution
        for workload in self.workloads.values():
            topology["workload_distribution"][workload.name] = {
                "type": workload.type.value,
                "nodes": [self.nodes[nid].name for nid in workload.deployed_nodes if nid in self.nodes],
                "replicas": workload.replicas
            }
        
        # Simulate connections between nodes
        node_ids = list(self.nodes.keys())
        for i, node1_id in enumerate(node_ids):
            for node2_id in node_ids[i+1:]:
                node1 = self.nodes[node1_id]
                node2 = self.nodes[node2_id]
                
                # Calculate distance between nodes
                distance = self._calculate_distance(
                    node1.location["lat"], node1.location["lon"],
                    node2.location["lat"], node2.location["lon"]
                )
                
                if distance < 5000:  # Within 5000 km
                    topology["connections"].append({
                        "from": node1.name,
                        "to": node2.name,
                        "distance_km": round(distance, 2),
                        "latency_ms": round(distance / 100, 2)  # Rough estimate
                    })
        
        return topology
    
    def _calculate_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """Calculate distance between two geographic points in km"""
        from math import radians, sin, cos, sqrt, atan2
        
        R = 6371  # Earth's radius in km
        
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * atan2(sqrt(a), sqrt(1-a))
        
        return R * c
    
    def _emit_event(self, event_type: str, data: Dict):
        """Emit event for real-time monitoring"""
        event = {
            "type": event_type,
            "timestamp": datetime.now().isoformat(),
            "data": data
        }
        self.event_queue.put(event)
        
        # Send to websocket clients if any
        for client in self.websocket_clients:
            try:
                client.send(json.dumps(event))
            except:
                pass
    
    def get_summary(self) -> Dict:
        """Get edge orchestration summary"""
        return {
            "total_nodes": len(self.nodes),
            "online_nodes": len([n for n in self.nodes.values() if n.status == "online"]),
            "total_workloads": len(self.workloads),
            "running_workloads": len([w for w in self.workloads.values() if w.status == "running"]),
            "total_deployments": len(self.deployments),
            "geographic_regions": len(set(n.location.get("region") for n in self.nodes.values())),
            "node_types": dict(Counter(n.type.value for n in self.nodes.values())),
            "workload_types": dict(Counter(w.type.value for w in self.workloads.values())),
            "average_node_utilization": np.mean([
                (n.capacity["cpu"] - n.available_capacity["cpu"]) / n.capacity["cpu"] * 100
                for n in self.nodes.values()
            ]),
            "last_rebalance": self.last_rebalance.isoformat()
        }


def main():
    """Test edge orchestration system"""
    print("üåê Edge Computing Orchestration System")
    print("=" * 50)
    
    # Initialize orchestrator
    orchestrator = EdgeOrchestrator()
    
    # Display registered nodes
    print("\nüìç Edge Nodes:")
    for node in orchestrator.nodes.values():
        print(f"  - {node.name} ({node.type.value})")
        print(f"    Location: {node.location['city']}, {node.location['country']}")
        print(f"    Capacity: CPU={node.capacity['cpu']}, Memory={node.capacity['memory']}GB")
        print(f"    Latency to cloud: {node.latency_to_cloud}ms")
    
    # Deploy some workloads
    print("\nüì¶ Deploying Edge Workloads...")
    
    # Real-time analytics workload
    analytics_workload = EdgeWorkload(
        id="wl-001",
        name="Real-time Analytics",
        type=WorkloadType.REAL_TIME_ANALYTICS,
        requirements={"cpu": 4, "memory": 16, "storage": 50, "network": 100},
        priority=8,
        latency_requirement=10,
        data_locality="us-east",
        deployment_strategy=DeploymentStrategy.LATENCY_OPTIMIZED,
        replicas=2,
        container_image="analytics:latest",
        environment_vars={"MODE": "streaming"},
        dependencies=[],
        status="pending",
        deployed_nodes=[],
        created_at=datetime.now(),
        metadata={}
    )
    
    deployments = orchestrator.deploy_workload(analytics_workload)
    print(f"  ‚úÖ Deployed {analytics_workload.name} to {len(deployments)} nodes")
    
    # AI inference workload
    ai_workload = EdgeWorkload(
        id="wl-002",
        name="AI Model Inference",
        type=WorkloadType.AI_INFERENCE,
        requirements={"cpu": 8, "memory": 32, "storage": 100, "network": 50},
        priority=9,
        latency_requirement=5,
        data_locality=None,
        deployment_strategy=DeploymentStrategy.RELIABILITY_OPTIMIZED,
        replicas=1,
        container_image="ai-inference:latest",
        environment_vars={"MODEL": "yolov5"},
        dependencies=[],
        status="pending",
        deployed_nodes=[],
        created_at=datetime.now(),
        metadata={}
    )
    
    deployments = orchestrator.deploy_workload(ai_workload)
    print(f"  ‚úÖ Deployed {ai_workload.name} to {len(deployments)} nodes")
    
    # IoT data processing
    iot_workload = EdgeWorkload(
        id="wl-003",
        name="IoT Data Processing",
        type=WorkloadType.IOT_PROCESSING,
        requirements={"cpu": 2, "memory": 8, "storage": 20, "network": 200},
        priority=6,
        latency_requirement=20,
        data_locality="us-west",
        deployment_strategy=DeploymentStrategy.COST_OPTIMIZED,
        replicas=1,
        container_image="iot-processor:latest",
        environment_vars={"PROTOCOL": "MQTT"},
        dependencies=[],
        status="pending",
        deployed_nodes=[],
        created_at=datetime.now(),
        metadata={}
    )
    
    deployments = orchestrator.deploy_workload(iot_workload)
    print(f"  ‚úÖ Deployed {iot_workload.name} to {len(deployments)} nodes")
    
    # Collect and display metrics
    print("\nüìä Edge Metrics:")
    metrics = orchestrator.collect_metrics()
    for metric in metrics[:3]:
        node = orchestrator.nodes[metric.node_id]
        print(f"  {node.name}:")
        print(f"    CPU: {metric.cpu_usage:.1f}%, Memory: {metric.memory_usage:.1f}%")
        print(f"    Network: In={metric.network_in:.0f}Mbps, Out={metric.network_out:.0f}Mbps")
        print(f"    Latency: {metric.latency:.1f}ms")
    
    # Predict failures
    print("\n‚ö†Ô∏è Failure Predictions:")
    predictions = orchestrator.predict_failures()
    if predictions:
        for pred in predictions[:2]:
            print(f"  - {pred['node_name']}: {pred['failure_probability']:.1%} chance of failure")
            print(f"    Recommended: {pred['recommended_action']}")
    else:
        print("  No imminent failures predicted")
    
    # Energy optimization
    print("\n‚ö° Energy Optimization:")
    energy_opt = orchestrator.optimize_energy_usage()
    print(f"  Current consumption: {energy_opt['current_consumption']:.0f}W")
    print(f"  Optimized consumption: {energy_opt['optimized_consumption']:.0f}W")
    print(f"  Potential savings: {energy_opt['savings_percentage']:.1f}%")
    
    # Get topology
    print("\nüó∫Ô∏è Edge Topology:")
    topology = orchestrator.get_edge_topology()
    print(f"  Nodes: {len(topology['nodes'])}")
    print(f"  Connections: {len(topology['connections'])}")
    print(f"  Geographic coverage: {list(topology['geographic_coverage'].keys())}")
    
    # Summary
    print("\nüìà Orchestration Summary:")
    summary = orchestrator.get_summary()
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    print("\n‚úÖ Edge orchestration system operational!")


if __name__ == "__main__":
    main()